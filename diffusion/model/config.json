{
  "lr": 0.001,
  "batch_size": 2048,
  "microbatch": 64,
  "learning_steps": 3000,
  "log_interval": 20,
  "save_interval": 1000,
  "eval_interval": 1000,
  "ema_rate": "0.9999",
  "resume_checkpoint": "none",
  "schedule_sampler": "lossaware",
  "diffusion_steps": 100,
  "noise_schedule": "sqrt",
  "timestep_respacing": "",
  "vocab": "gpt2",
  "use_plm_init": "gpt2",
  "vocab_size": 0,
  "config_name": "uer/gpt2-chinese-ancient",
  "notes": "folder-notes",
  "data_dir": "./data",
  "dataset": "24history",
  "checkpoint_path": "checkpoint-path",
  "seq_len": 256,
  "hidden_t_dim": 768,
  "hidden_dim": 768,
  "dropout": 0.1,
  "use_fp16": false,
  "fp16_scale_growth": 0.001,
  "seed": 102,
  "gradient_clipping": -1.0,
  "weight_decay": 0.0,
  "learn_sigma": false,
  "use_kl": false,
  "predict_xstart": true,
  "rescale_timesteps": true,
  "rescale_learned_sigmas": false,
  "sigma_small": false,
  "emb_scale_factor": 1.0
}